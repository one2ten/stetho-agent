"""ì‘ë‹µ ìƒì„± ë…¸ë“œ â€” ì‚¬ìš©ì ëª¨ë“œì— ë§ëŠ” ìµœì¢… ê¶Œê³  ìƒì„±"""
from __future__ import annotations

import logging
from pathlib import Path

from agents.state import AgentState
from models.llm_client import LLMClient
from models.literature_search import MedicalSearchClient

logger = logging.getLogger(__name__)

_PROMPTS_DIR = Path(__file__).resolve().parent.parent.parent / "prompts"


def _load_prompt(user_mode: str) -> str:
    """ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë”©"""
    if user_mode == "professional":
        path = _PROMPTS_DIR / "recommendation_professional.md"
    else:
        path = _PROMPTS_DIR / "recommendation_general.md"

    if path.exists():
        return path.read_text(encoding="utf-8")

    if user_mode == "professional":
        return "ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì—ê²Œ ë³´ê³ í•˜ëŠ” AIì…ë‹ˆë‹¤. ì „ë¬¸ ì˜í•™ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    return "ë‹¹ì‹ ì€ ì¼ë°˜ì¸ì—ê²Œ ê±´ê°• ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” AIì…ë‹ˆë‹¤. ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”."


def recommendation_node(state: AgentState) -> dict:
    """
    ì‘ë‹µ ìƒì„± ë…¸ë“œ.

    - user_modeì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì„ íƒ (general / professional)
    - ìœ„í—˜ë„ high/critical ì‹œ ì¦‰ì‹œ ì˜ë£Œ ìƒë‹´ ê¶Œê³  ì¶”ê°€
    - ë¬¸í—Œ ì°¸ì¡° ì •ë³´ í¬í•¨
    """
    user_mode = state.get("user_mode", "general")
    synthesis = state.get("synthesis", "")
    risk = state.get("risk_assessment")
    literature = state.get("literature_references")

    logger.info("ì‘ë‹µ ìƒì„± ì‹œì‘: mode=%s, risk=%s", user_mode, risk.level if risk else "N/A")

    # ìœ„í—˜ë„ ê²½ê³  ë¬¸êµ¬
    risk_warning = ""
    if risk and risk.level in ("high", "critical"):
        risk_warning = (
            "\n\nğŸš¨ **ì¤‘ìš”**: ì´ í™˜ìëŠ” ë†’ì€ ìœ„í—˜ë„ë¡œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. "
            "ê°€ëŠ¥í•œ ë¹¨ë¦¬ ì˜ë£Œ ì „ë¬¸ê°€ì˜ ì§„ë£Œë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        )

    # ë¬¸í—Œ ì°¸ì¡° í…ìŠ¤íŠ¸
    lit_text = ""
    if literature:
        lit_text = MedicalSearchClient.format_references_for_llm(literature)

    risk_info = ""
    if risk:
        risk_info = (
            f"ìœ„í—˜ë„: {risk.level} ({risk.score:.0f}ì )\n"
            f"ìœ„í—˜ ìš”ì¸: {', '.join(risk.factors)}\n"
            f"ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”: {'ì˜ˆ' if risk.immediate_action_needed else 'ì•„ë‹ˆì˜¤'}\n"
        )

    user_prompt = (
        f"=== ì¢…í•© ë¶„ì„ ê²°ê³¼ ===\n{synthesis}\n\n"
        f"=== ìœ„í—˜ë„ í‰ê°€ ===\n{risk_info}\n"
    )
    if lit_text:
        user_prompt += f"\n{lit_text}\n"

    user_prompt += (
        "\nìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ìì—ê²Œ ì „ë‹¬í•  ìµœì¢… ê¶Œê³ ì‚¬í•­ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
        "í¬í•¨í•  ë‚´ìš©: 1) í˜„ì¬ ìƒíƒœ ìš”ì•½ 2) ê¶Œì¥ ì¡°ì¹˜ 3) ìƒí™œ ìŠµê´€ ì¡°ì–¸ 4) ì¶”ê°€ ê²€ì‚¬ í•„ìš” ì—¬ë¶€"
    )

    try:
        llm = LLMClient()
        system_prompt = _load_prompt(user_mode)
        recommendation = llm.generate(user_prompt, system_prompt=system_prompt)

        # ìœ„í—˜ë„ ê²½ê³  ì¶”ê°€
        if risk_warning:
            recommendation = risk_warning + recommendation

        logger.info("ì‘ë‹µ ìƒì„± ì™„ë£Œ: %dì", len(recommendation))
        return {"recommendation": recommendation}
    except Exception as e:
        error_msg = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        logger.error(error_msg)
        return {"recommendation": error_msg}
